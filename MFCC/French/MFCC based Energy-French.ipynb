{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"13RoH44v8xAlXi8zz850rJhSTD1tN2BCH","authorship_tag":"ABX9TyNBWuvxZKHKOrf1wlZ8UHWz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xQ6XW_ODojxS"},"outputs":[],"source":["pip install python_speech_features"]},{"cell_type":"code","source":["from python_speech_features import mfcc\n","from sklearn.mixture import GaussianMixture\n","import scipy as sc\n","import numpy as np\n","import os\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"i79OfDBppeAM","executionInfo":{"status":"ok","timestamp":1682732779051,"user_tz":-60,"elapsed":1673,"user":{"displayName":"Agenda Universitaire","userId":"16062728775578872880"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["dir = \"/content/drive/MyDrive/Projet/Langues/Dataset/French\""],"metadata":{"id":"bEIjKTGcpia8","executionInfo":{"status":"ok","timestamp":1682732784899,"user_tz":-60,"elapsed":269,"user":{"displayName":"Agenda Universitaire","userId":"16062728775578872880"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["folders_out = [\"Train\", \"Test\"]\n","folders_in = [\"F\", \"H\"]\n","mfcc_folder = \"/content/drive/MyDrive/Projet/Langues/MFCC/French\"\n","\n","for folder_out in folders_out:\n","  for folder_in in folders_in:\n","\n","    data_folder = dir + (\"/\") + folder_out + (\"/\") + folder_in\n","    audio_files = os.listdir(data_folder)\n","    audio_files = [filename for filename in audio_files if filename.endswith(('.wav'))]\n","\n","    for audio_file in audio_files:\n","      \n","      basename = audio_file.split('.')[0]+(\"_mfcc\")\n","\n","      rate, data = sc.io.wavfile.read(os.path.join(data_folder, audio_file))\n","      mfcc_feat = mfcc(data, rate)\n","      mfcc_feat_arr = np.asarray(mfcc_feat)\n","\n","      path = mfcc_folder + (\"/\") + folder_out + (\"/\") + folder_in\n","      np.savetxt(path+(\"/\")+basename+\".txt\", mfcc_feat_arr, delimiter=',')   "],"metadata":{"id":"Q08_Q_BJp3G0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Silence Removal**"],"metadata":{"id":"JzTjSMxYyHqZ"}},{"cell_type":"code","source":["gmm = GaussianMixture(n_components=2, covariance_type='full')\n","\n","for folder_out in folders_out:\n","  for folder_in in folders_in:\n","\n","    data_folder = mfcc_folder + (\"/\") + folder_out + (\"/\") + folder_in\n","    mfcc_files = os.listdir(data_folder)\n","    mfcc_files = [filename for filename in mfcc_files if filename.endswith('txt')]\n","\n","    for filename in mfcc_files :\n","\n","      basename = filename.split('.')[0] + (\"_no_silence\")\n","\n","      mfcc = np.loadtxt(os.path.join(data_folder, filename), delimiter=',')\n","      print(\"Avant : \", mfcc.shape)\n","\n","      energies = np.sum(np.square(mfcc), axis=1)\n","      energies = energies.reshape(-1, 1)\n","\n","      gmm.fit(energies)\n","      means = gmm.means_\n","      silence_component = np.argmin(means)\n","      silence_threshold = means[silence_component] - 2 * np.sqrt(gmm.covariances_[silence_component])\n","      \n","      non_silent_mask = energies > silence_threshold\n","      mfcc_no_silence = energies[non_silent_mask]\n","      print(\"Apr√®s : \", mfcc_no_silence.shape)\n","\n","      path = mfcc_folder + (\"/Preprocessing/\") + folder_out + (\"/\") + folder_in\n","      np.savetxt(path+(\"/\")+basename+\".txt\", mfcc_no_silence, delimiter=',')"],"metadata":{"id":"oi0fPWeeq3Pz"},"execution_count":null,"outputs":[]}]}